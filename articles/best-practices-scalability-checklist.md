<properties
   pageTitle="スケーラビリティのチェックリスト|Microsoft Azure"
   description="Azure 自動スケールの設計に関するスケーラビリティのチェックリスト ガイダンス。"
   services=""
   documentationCenter="na"
   authors="dragon119"
   manager="masimms"
   editor=""
   tags=""/>

<tags
   ms.service="best-practice"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="04/28/2015"
   ms.author="masashin"/>

# スケーラビリティのチェックリスト

![](media/best-practices-scalability-checklist/pnp-logo.png)

## サービスの設計
- **ワークロードを分割します**します。 プロセスのパーツを別個に分解できるように設計します。また、処理内容の独立の一般規則および単一責任の法則に従って、各パーツのサイズは最小限にします。 これにより、各コンピューティング ユニット (ロールまたはデータベース サーバーなど) を最大限に使用できるようにコンポーネントのパーツを分散できます。また、特定のリソースのインスタンスを追加することで、アプリケーションのスケーリングが容易になります。 詳細については、次を参照してください。 [コンピューティング パーティション分割ガイダンス](https://msdn.microsoft.com/library/dn568099.aspx)します。
- **拡張するためのデザイン**します。 スケーリングにより、アプリケーションは、ロール、キュー、および使用する他のサービスのインスタンスの数を増減することで、変動負荷に対応できます。 ただし、アプリケーションを設計する際には、次の点を考慮に入れる必要があります。 たとえば、アプリケーションとそれが使用するサービスはステートレスにして、要求をどのインスタンスにもルーティングできるようにする必要があります。また、特定のインスタンスの追加または削除によって、現行ユーザーに悪影響が及ぶことがないようにします。 さらに、インスタンスの追加/削除を自動検出して、インスタンスの再構成を行うしくみを実装して、アプリケーション内のコードが必要なルーティングを実行できるようにする必要があります。 たとえば、Web アプリケーションは一連のキューをラウンド ロビン方式で使用して、worker ロールで実行しているバックグラウンド サービスに要求をルーティングする場合があります。 Web アプリケーションは、要求を正しくルーティングして、アプリケーションへの負荷を均等にするために、キューの数の変更を検出できる必要があります。
- **ユニットとしてスケール**します。 成長に合わせてリソースを追加するように計画します。 リソースごとに、スケーリングの上限を確認し、シャーディングまたは分解を使用して、これらの限度を超える必要があります。 明確に定義されたリソースのセットを単位として、システムのスケール ユニットを判別します。 これにより、スケールアウト操作の適用が容易になるだけでなく、システム全体のある部分でリソースが不足しているために制限が課され、アプリケーションに悪影響を及ぼす可能性を避けることができます。  追加 x などの web ロールとワーカー ロールの数が必要になるその他のキューの数を y のスケール ユニットはで構成するために、ロールで生成されるその他のワークロードを処理するストレージ アカウント数の z web および worker ロールでは、x _y_ キュー、および _z_ ストレージ アカウント。 1 つ以上のスケール ユニットを追加することでスケーリングが容易になるように、アプリケーションを設計してください。
- **クライアント アフィニティを回避**します。 可能であれば、どのインスタンスにも要求をルーティングできるように、またインスタンスの数に影響されずに済むように、アプリケーションでアフィニティを要求しないようにします。 これにより、各ユーザーの状態情報を格納、取得、保守するためのオーバーヘッドが生じることもなくなります。
- **プラットフォーム自動スケール機能を活用**します。 ホスティング プラットフォームが Azure Autoscaling などの自動スケール機能をサポートする場合、組み込みのメカニズムで要求を満たせない場合を除き、カスタムまたはサードパーティのメカニズムではなく自動スケール機能を使用してください。 可能な限り、スケジュールされたスケーリング ルールを使用し、起動時の遅延なしでリソースを使用可能にします。しかし、必要に応じてリアクティブ自動スケールをルールに追加し、予期しない要求の変化に対応する必要があります。 サービス管理 API で自動スケール操作を使用して、自動スケールを微調整したり、Web ポータルで使用可能な構成オプション以外にカスタム カウンターをルールに追加したりできます。 詳細については、ページを参照してください。 [自動スケール ガイダンス](best-practices-auto-scaling.md)します。
- **バック グラウンド タスクとして負荷の高い CPU/IO タスクをオフロード**します。 サービスへの要求の実行に長時間かかったり、かなりのリソースを消費したりすることが予測される場合、この要求の処理を別個のタスクにオフロードします。 (ホスティング プラットフォームに応じ、) worker ロールまたはバックグラウンド ジョブを使用して、これらのタスクを実行します。 この戦略を使用すると、サービスはさらに多くの要求を引き続き受信したり、即座に対応したりすることが可能になります。  詳細については、次を参照してください。 [ジョブのガイダンスをバック グラウンド](best-practices-background-jobs.md)します。
- **バック グラウンド タスクの作業負荷を分散**します。 多くのバックグラウンド タスクがある場合、またはタスクの実行に相当の時間かリソースが必要な場合、複数のコンピューティング ユニット (worker ロールまたはバックグラウンド ジョブなど) に作業を分散します。  [競合コンシューマー パターン](https://msdn.microsoft.com/library/dn568101.aspx) は 1 つの可能なソリューションを提供します。
- **移行を検討してください、 _シェアード ナッシング_ アーキテクチャ**します。 シェアード ナッシング アーキテクチャでは、ノードは独立しており、自律的であり、共有システムやストレージなどの単一競合箇所がありません。 理論上、そのようなシステムはほぼ無制限にスケールできます。 一般に、完全なシェアード ナッシング アプローチはほとんどのアプリケーションで実用的ではありませんが、スケーラビリティの向上を考慮に入れた設計には適している場合があります。 たとえば、サーバー側のセッション状態、クライアント アフィニティ、データのパーティション分割の使用を避けることは、シェアード ナッシング アーキテクチャを使用する良い例です。

## データ管理

- **データのパーティション分割を使用して**します。 データを複数のデータベースおよびデータベース サーバーに分割するか、またはこのパーティション分割を透過的に実行できるデータ ストレージ サービスを使用するようにアプリケーションを設計します (サービスの一例として、Azure SQL Database Elastic Scale や Azure テーブル ストレージがあります)。 このアプローチを使用すると、パフォーマンスを最大化すると同時に、スケーリングを容易にすることが可能です。 パーティション分割には、水平的パーティション分割、垂直的パーティション分割、および機能的パーティション分割など、さまざまな技法があります。これらを組み合わせて使用すると、クエリのパフォーマンスの向上、シンプル化されたスケーラビリティ、より柔軟性のある管理、可用性の向上から得られるメリットを最大限に活用できるだけでなく、保持されるデータとデータ ストアの種類を一致させることができます。 さらに、データ タイプに応じて異なる種類のデータ ストアを使用したり、特定のデータ タイプに合わせて最適化した場合の状態に基づいてタイプを選択したりすることを検討してください。 これには、リレーショナル データベースの代わりに、またはリレーショナル データベースと同時に、テーブル ストレージ、ドキュメント データベース、列ファミリ データ ストアを使用することが含まれます。 詳細については、次を参照してください。 [データのガイダンスをパーティション分割](best-practices-data-partitioning.md)します。
- **最終的な一貫性のための設計**します。 結果整合性を取り入れると、複数のストアに分割された関連データを同期するために必要な時間が短縮されたり、またはその時間がなくなったりするため、スケーラビリティが向上します。 ただしその反面、データはその読み取り時に常に整合性があるとは限りません。また、書き込み操作によっては競合が生じる場合があります。 結果整合性は、同じデータの読み取りは頻繁に行われるが、書き込みはめったに行われない場合に有効です。 詳細については、[データ整合性のガイダンス] を参照してください ([insertlink])。
- **コンポーネントとサービス間の煩雑なやりとりを削減**します。 設計を避けるため _煩雑な_ サービスについては、インターフェイスに、アプリケーションがサービスへの呼び出しを行うために必要な場所 (少量のデータをそれぞれ返します) すべてのデータを返すことができる 1 つの呼び出しではなく。 サービスまたはコンポーネントの呼び出しに著しい待ち時間が生じる場合、可能であれば関連するいくつかの操作を組み合わせて 1 つの要求にまとめてください。 そうすることで、パフォーマンスの監視と複雑な操作の最適化を容易に実行できます。たとえば、データベースでストアード プロシージャを使用して複雑なロジックをカプセル化し、ラウンド トリップとびリソース ロックの回数を減らすことができます。 
- **キューを使用して、高速なデータ書き込みを負荷を均等**します。 サービス要求の急増がそのサービスを圧迫し、障害を悪化させる可能性があります。 これを防ぐためには、実装することを検討、 [Queue-based Load Leveling パターン](https://msdn.microsoft.com/library/dn589783.aspx)します。 タスクとそのタスクが呼び出すサービスの間のバッファーの役目をするキューを使用して、サービスの障害やタスクのタイム アウトにつながる可能性がある断続的な大きい負荷を平準化することができます。
- **データ ストアへの負荷を最小限に抑える**します。 データ ストアは、処理のボトルネック、コストの高いリソースでは一般的になり、スケール アウトする多くの場合、簡単です。 可能であれば、データ ストアからロジック (XML 文書や JSON オブジェクトの処理など) を除去し、アプリケーション内で処理を実行してください。 たとえば、XML を (ストレージの不明瞭な文字列以外として) データベースに渡す代わりに、アプリケーション層内で XML をシリアル化/逆シリアル化し、データ ストアにとってネイティブな形式で渡します。 通常、アプリケーションをスケールアウトするほうがデータ ストアをスケールアウトするよりはるかに容易です。したがって、多くのコンピューティング処理を要する処理はできるだけアプリケーション内で行うようにする必要があります。
- **取得するデータの量を最小限に抑える**します。 列を指定し、条件を使用して行を選択することにより、必要なデータのみ取得します。 テーブル値パラメーターおよび適切な分離レベルを使用します。 ETags などのメカニズムを使用してデータを不必要に取得しないようにします。
- **キャッシングを積極的に使用**します。 可能な限りキャッシングを使用して、データを生成または配信するリソースおよびサービスへの負荷を削減してください。 通常、キャッシュは、比較的静的なデータ、または取得のためにかなりの量の処理を必要とするデータに適しています。 キャッシングは、データ アクセスおよび UI の生成などのアプリケーションの各層で、必要に応じてすべてのレベルで行う必要があります。 詳細については、次を参照してください。、 [キャッシュ ガイダンス](best-practices-caching.md)します。
- **データの増大および保存に対処**します。 アプリケーションが格納するデータの量は、時間の経過とともに増大します。 この増大により、ストレージ コストは上昇し、データ アクセス時の待ち時間も増加します。このことはアプリケーションのスループットおよびパフォーマンスに影響を与えます。 アクセスされなくなっている古いデータを定期的にアーカイブするか、めったにアクセスしないデータを、アクセスの待ち時間がより長いが、コスト効率の良い長期保存向けのストレージに移動したりできる可能性があります。
- **効率の良いバイナリ形式を使用して Dto を最適化**します。 データ転送オブジェクトはアプリケーションの層の間で何度も渡されるため、サイズを最小化すれば、リソースおよびネットワークへの負荷が軽減されます。 ただし、データが使用される各ロケーションでデータを必要な形式に変換するオーバーヘッドと負荷軽減とのバランスを保ち、コンポーネントの再利用を容易にするために相互運用性の最も高い形式を採用してください。
- **キャッシュ制御を設定**します。 可能な限り出力キャッシングまたはフラグメント キャッシングを使用して、処理負荷を最小限に抑えるようにアプリケーションを設計および構成します。
- **クライアント側キャッシングを有効にする**です。 Web アプリケーションでは、キャッシュ可能なコンテンツ上でキャッシュ設定を有効にする必要があります。  通常、規定では無効になっています。 プロキシ サーバーおよびクラアント上でコンテンツのキャッシングを有効にするために、適切なキャッシュ制御ヘッダーを提供するようサーバーを構成します。
- **Azure blob ストレージおよび CDN を使用して、アプリケーションの負荷を軽減する**です。 イメージ、リソース、スクリプト、スタイル シートといった静的または比較的静的なパブリック コンテンツを BLOB ストレージに格納することを検討してください。 このアプローチにより、要求ごとにこのコンテンツを動的に生成することで発生する負荷をアプリケーションから除くことができます。 さらに、CDN を使用してこのコンテンツをキャッシュし、クライアントに配信することを検討してください。 CDN を使用すると、クライアント側のパフォーマンスを向上できます。なぜなら、コンテンツは地理的に最も近くにある、CDN キャッシュを利用できるデータセンターから配信されるからです。 詳細については、次を参照してください。、 [CDN のガイダンス](best-practices-cdn.md)します。

- **最適化し、SQL クエリおよびインデックスのチューニング**します。 T-SQL ステートメントまたはコンストラクトの中には、パフォーマンスに影響を与えるものがあります。この影響は、ストアード プロシージャでコードを最適化することにより軽減できます。 などの変換 **datetime** の種類を **varchar** と比較する前に、 **datetime** リテラル値を避ける必要があります: 日付/時刻比較関数の代わりに使用します。 適切なインデックスがないと、クエリの実行が遅くなる可能性があります。 オブジェクト/リレーショナル マッピング (ORM) フレームワークを使用する場合、その動作およびデータ アクセス層のパフォーマンスへの影響を理解しておく必要があります。 詳細については、次を参照してください。 [クエリのチューニング](https://technet.microsoft.com/library/ms176005.aspx)します。
- **データの非正規化を検討してください**します。 データの非正規化により、重複や不整合を避けることができます。 しかし、複数のインデックスを保守する、参照整合性を検査する、小さいデータ チャンクに複数回アクセスを実行する、テーブルを結合してデータを再アセンブルするといった作業が必要になるため、オーバーヘッドが生じて、パフォーマンスに影響を与える可能性があります。 データ ストアへの負荷を軽減するために、追加のストレージ ボリュームおよび重複を受け入れられるかどうかを検討してください。 また、データ ストアへの負荷を軽減するために、参照整合性の管理などのタスクの引き継ぎにアプリケーションそのものを利用できるかどうか (通常は、スケーリングがより容易です) も検討してください。 詳細については、次を参照してください。 [データのガイダンスをパーティション分割](https://github.com/mspnp/azure-guidance/blob/master/Data%20partitioning.md)します。

## サービスの実装
- **非同期呼び出しを使用して**します。 I/O またはネットワーク帯域幅によって制限される可能性があるリソースまたはサービス、あるいは著しい待ち時間があるリソースまたはサービスにアクセスする際には、呼び出し側のスレッドをロックしないために、可能な限り非同期コードを使用します。 非同期動作を実行するには、タスク ベースの非同期パターンを実装します。 詳細については、次を参照してください。、 [タスクベースの非同期パターン (TAP)](https://msdn.microsoft.com/library/hh873175.aspx) 、Microsoft web サイトのページです。
- **リソースのロックを避け、代わりにオプティミスティック アプローチを使用して**します。 ストレージなどのリソースまたは著しい待ち時間がある他のサービスへのアクセスをロックしないでください。なぜなら、パフォーマンス低下の主な原因は、このロックだからです。 ストレージへの書き込みなどの並行操作の管理には、常にオプティミスティック アプローチを使用してください。また、競合の管理には、ストレージ層の機能を使用してください。 分散化アプリケーションでは、データの一貫性は最終的にしか保たれない場合があります。
- **高遅延で低帯域幅のネットワーク経由で高圧縮可能なデータを圧縮**します。 Web アプリケーションではほとんどの場合、アプリケーションによって生成され、ネットワーク上で渡される最大のデータは、クライアントの要求に対する HTTP 応答です。 この大きさは、HTTP 圧縮により、大幅に縮小できます。特に静的コンテンツの場合には効果的です。 これにより、コストを削減できるだけでなく、ネットワークへの負荷も削減できます。ただし、動的コンテンツの圧縮は、部分的に高い負荷がサーバーに適用されます。 より汎用的な他の環境では、データ圧縮を圧縮して転送されるデータの量を削減することで、転送時間およびコストを最小化できます。ただし、圧縮プロセスおよび展開プロセスによるオーバーヘッドが発生します。 そのため、圧縮は、パフォーマンスに明らかなメリットがある場合にのみ使用する必要があります。 JSON やバイナリ エンコーディングなど、他のシリアル化方式では、パフォーマンスにそれほど影響を与えずに、ペイロード サイズを減らすことができます。一方、XML ではパフォーマンスへの負荷が増加する可能性があります。
- **接続およびリソースが使用されている時間を最小限に抑える**します。 接続およびリソースは、必要な期間だけ維持します。 たとえば、接続を開くのはできるだけ遅く、接続プールに返すのはできるだけ早くします。 リソースの取得はできるだけ遅くし、できるだけ早く解放します。
- **必要な接続の数を最小限に抑える**します。 サービス接続はリソースを消費します。 可能な限り必要な数を制限し、可能な場合には既存の接続を再利用するようにします。 たとえば、認証の実行後、必要に応じて権限借用を使用し、コードを特定の ID として実行します。 これにより、接続が再利用されるため、接続プールを最大限に活用できます。 

    > [AZURE.NOTE]: * * サービスに固有のガイドラインに従っている限りにいくつかのサービスの Api が接続に自動的に再利用します。 アプリケーションで使用される各サービスに対して接続の再利用を有効にする条件を理解しておくことが重要です。
- **ネットワークの使用を最適化するためにバッチで要求を送信**します。 たとえば、キューにアクセスするときにはメッセージの送信および読み取りをバッチで行い、ストレージまたはキャッシュにアクセスするときには複数の読み取りまたは書き込みをバッチとして実行します。 このように、ネットワーク上の呼び出しの数を減らすことで、サービスおよびデータ ストアの効率を最大限に高めることができます。
- **サーバー側のセッション状態を格納しないで済む** 可能な場合です。 通常、サーバー側のセッション状態の管理にはクライアント アフィニティが必要です (つまり、各要求を同じサーバー インスタンスにルーティングします)。これはシステムのスケール能力に影響を与えます。 理想的には、クライアントが使用するサーバーに対して、クライアントをステートレスに設計する必要があります。 ただし、アプリケーションがセッション状態を維持する必要がある場合、機密性の高いデータまたはクライアントごとの大量データは、アプリケーションのすべてのインスタンスがアクセスできる分散されたサーバー側のキャッシュに格納してください。
- **テーブル ストレージ スキーマを最適化**します。 Azure テーブル ストレージなどのように、テーブルおよび列の名前をクエリごとに渡して処理する必要があるテーブル ストアを使用する場合、このオーバーヘッドを減らすために短い名前の使用を検討してください。 ただし、読みやすさや管理の容易さを犠牲にせず、そのうえで直観的でない短い名前を使用してください。
- **非同期操作を実行する TPL を利用して**します。 タスク並列ライブラリ (TPL) により、I/O バウンド型の操作を実行する非同期コードの書き込みが容易になります。 使用 _configureawait (false)_ 可能であれば特定の同期コンテキストに対する継続の依存関係を排除し、スレッドのデッドロックが発生する可能性を軽減します。
- **デプロイメント中またはアプリケーションのスタートアップ時に、リソースの依存関係を作成**します。 存在しない場合に、リソースを作成するリソースの存在をテストをするメソッドを繰り返し呼び出して (などのメソッド _CloudTable.CreateIfNotExists_ と _CloudQueue.CreateIfNotExists_ Azure ストレージ クライアント ライブラリのこのパターンに従います)。 ストレージ テーブルまたはストレージ キューにアクセスする前に、毎回これらのメソッドが呼び出される場合、著しいオーバーヘッドが生じる可能性があります。 代わりに、アプリケーションが展開されるとき、または初回の始動時に、必要なリソースを作成 (1 回の呼び出し _CreateIfNotExists_ スタートアップ フォルダーには、各リソース web またはワーカー ロール用のコードはもかまいません)。 ただし、存在しないリソースに対してコードがアクセスしようとする場合に生じる可能性がある例外を必ず処理します。 こうした状況では、例外を記録し、リソースが見つからないことをオペレーターに可能な限り警告する必要があります。 ある状況では、見つからないリソースを例外処理コードの一部として作成することが適切です。しかし、リソースが見つからない理由として、プログラミング エラー (リソース名のスペルミスなど) や他のインフラストラクチャ レベルの問題が考えられるため、このアプローチは慎重に採用する必要があります。
- **軽量フレームワークを使用**します。 リソース使用量、実行時間、アプリケーションへの全体的な負荷を最小限にするために、使用する API およびフレームワークを慎重に検討します。 たとえば、Web API を使用してサービス要求を処理すると、アプリケーションのフットプリントが小さくなり、実行速度が向上します。しかし、WCF の追加機能が必要となるような高度のシナリオには適していない場合があります。
- **サービス アカウントの数を最小限に抑えることを検討してください**します。 たとえば、接続に制限が課されているリソースまたはサービスにアクセスしたり、維持する接続の数を少なくするとパフォーマンスが向上したりする場合は、固有のアカウントを使用します。 このアプローチは、データベースなどのサービスには一般的ですが、元のユーザーの権限借用であるため、操作を正確に監査する能力に影響する可能性があります。
- **パフォーマンス プロファイリングを実行し、ロード テスト** 最終リリースは、アプリケーションを実行するようにすると、スケーリングが要求どおりテスト ルーチンの一部として、開発中です。 このテストは、運用プラットフォームと同じタイプのハードウェアに対して、さらに運用中に生じるデータおよびユーザー負荷と同じタイプおよび数量を用いて実行する必要があります。 詳細については、ページを参照してください。 [クラウド サービスのパフォーマンスをテストする](https://msdn.microsoft.com/library/azure/hh369930.aspx) 、Microsoft web サイトです。


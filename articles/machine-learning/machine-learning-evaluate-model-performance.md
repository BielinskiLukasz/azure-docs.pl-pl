<properties 
    pageTitle="Azure Machine Learning でモデルのパフォーマンスを評価する方法 | Microsoft Azure" 
    description="Azure Machine Learning でモデルのパフォーマンスを評価する方法を説明します。" 
    services="machine-learning"
    documentationCenter="" 
    authors="garyericson" 
    manager="paulettm" 
    editor="cgronlun"/>

<tags 
    ms.service="machine-learning" 
    ms.workload="data-services" 
    ms.tgt_pltfrm="na" 
    ms.devlang="na" 
    ms.topic="article" 
    ms.date="12/04/2015" 
    ms.author="bradsev;garye" />


# Azure Machine Learning でモデルのパフォーマンスを評価する方法

ここでは、Azure Machine Learning Studio でモデルのパフォーマンスを評価する方法を取り上げ、その操作で使用できるメトリックを簡単に説明します。 以下の 3 種類の学習のシナリオを取り上げます。 

* 回帰
* 二項分類 
* 多クラス分類

[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]


モデルのパフォーマンスの評価は、データ サイエンス プロセスの重要な段階の 1 つです。 その評価は、トレーニングしたモデルによるデータセットのスコア付け (予測) がどれほど成功したかを示す指標になります。 

Azure Machine Learning では 2 つのおもな機械学習モジュールによってモデルの評価: [モデルの評価] [- モデルの評価] と [モデルのクロス検証] [クロス検証のモデル] です。 これらのモジュールを使用すれば、機械学習と統計情報でよく使用されるさまざまなメトリックの観点からモデルのパフォーマンスを確認できます。

##評価とクロス検証##
評価とクロス検証は、モデルのパフォーマンスを測定する標準的な方法です。 どちらの場合も評価メトリックが生成されるので、そのメトリックを確認したり、他のモデルと比較したりできます。

[モデルの評価][評価モデル] に入力としてスコア付けされたデータセットが必要ですが (または、2 つのケースたい 2 つのモデルのパフォーマンスを比較する)。 これは、[モデルのトレーニング] の [モデルのトレーニング] モジュールを使用してモデルをトレーニングし、結果を評価する前に、[モデルのスコア付け] の [モデルのスコア付け] モジュールを使用して一部のデータセットに予測を作成する必要があることを意味します。 評価にに基づいて、スコア付けされたラベル/確率と実際のラベルは、[モデルのスコア付け] の [モデルのスコア付け] モジュールから出力します。

あるいは、クロス検証を使用して、入力データの各サブセットに対して 10 分割のトレーニング/スコア付け/評価の操作を自動的に実行することもできます。 その場合、入力データは 10 分割され、1 つはテスト用、残りの 9 つはトレーニング用になります。 このプロセスが 10 回繰り返され、評価メトリックは平均化されます。 そのようにして、モデルが新しいデータセットにどの程度汎用化されるかを確認できます。 [モデルのクロス検証] の [クロス検証のモデル] モジュールでは、未トレーニングのモデルとラベルの付いたデータセットと、結果の平均値だけでなく、10 のフォールドのそれぞれの評価結果を出力します。

以降のセクションでおは単純な回帰モデルと分類モデルを構築し、[モデルの評価] [- モデルの評価] と [モデルのクロス検証] の [クロス検証のモデル] モジュールの両方を使用して、パフォーマンスを評価します。

##回帰モデルの評価##
自動車の大きさや馬力やエンジンの仕様などに基づいて価格を予測するとします。 これは、一般的な回帰問題では、場所、ターゲット変数 (*価格*) は継続的な数値を指定します。 自動車のさまざまな特徴の値に基づいて価格を予測するシンプルな線形回帰モデルを作成できます。 この回帰モデルを使用して、トレーニングで使用したのと同じデータセットのスコア付けを行うことができます。 すべての自動車の価格を予測したら、その予測と実際の価格の差異の平均値に基づいてモデルのパフォーマンスを評価できます。 これを示すためには、使用して、 *自動車価格データ (生データ) データセット* で使用できる、 **保存されたデータセット** Azure Machine Learning Studio でのセクションです。
 
###実験の作成###
Azure Machine Learning Studio で以下のモジュールをワークスペースに追加します。

- 自動車価格データ (生データ)
- [線形回帰][線形回帰]
- [モデルのトレーニング][モデルのトレーニング]
- [モデルのスコア付け][モデルのスコア付け]
- [モデルの評価][評価モデル]


図 1 のように、ポートに接続し、[モデルのトレーニング] [モデルのトレーニング] モジュールのラベル列を設定 *価格*します。
 
![回帰モデルの評価](media/machine-learning-evaluate-model-performance/1.png)

図 1. 回帰モデルの評価。

###評価結果の確認###
実験を実行すると、[モデルの評価] [- モデルの評価] モジュールの出力ポートをクリックし、選択 *視覚化* 評価結果を確認します。 回帰モデルで使用できる評価メトリックは: *平均絶対誤差*, 、*二乗平均絶対誤差*, 、*相対絶対誤差*, 、*相対二乗誤差*, 、および *決定係数*します。

ここでは、予測の値と実際の値の差異のことを「誤差」といいます。 予測の値と実際の値の差が負の値になることもあるので、通常は、この差の絶対値または 2 乗が計算され、すべての事例の誤差が全体でどれほどの大きさになっているかを確認します。 誤差のメトリックでは、実際の値に対する予測の値の平均偏差に基づいて回帰モデルの予測パフォーマンスを測定します。 誤差の値が小さければ小さいほど、モデルの予測が正確だということになります。 全体の誤差のメトリックが 0 であれば、そのモデルはデータに完璧に適合しています。

決定係数 (R 2 乗) も、モデルとデータがどれほど適合しているかを測定するための標準的な方法です。 これは、モデルで説明される変動の比率として解釈できます。 この場合は、比率が高いほど良く、1 は完璧に適合している状態です。
 
![線形回帰の評価メトリック](media/machine-learning-evaluate-model-performance/2.png)

図 2. 線形回帰の評価メトリック。

###クロス検証の使用###
前述のように、繰り返しのトレーニング、スコア付け/評価を自動的にモジュールを使用して、[モデルのクロス検証] [クロス検証のモデル] を実行できます。 ここで必要なは、データセット、トレーニングしていないモデル、および [モデルのクロス検証] [クロス検証のモデル] モジュール (次の図を参照してください)。 ラベル列を設定する必要があります *価格* [モデルのクロス検証] [クロス検証のモデル] モジュールのプロパティでします。

![回帰モデルのクロス検証](media/machine-learning-evaluate-model-performance/3.png)

図 3: 回帰モデルのクロス検証。

実験を実行した後は、[モデルのクロス検証] [クロス検証のモデル] モジュールの右側の出力ポートをクリックして、評価の結果を検査できます。 それぞれの反復処理 (分割処理) の詳細と、各メトリックの結果の平均値が表示されます (図 4)。
 
![回帰モデルのクロス検証の結果](media/machine-learning-evaluate-model-performance/4.png)

図 4: 回帰モデルのクロス検証の結果。

##二項分類モデルの評価##
二項分類のシナリオでは、ターゲット変数には 2 つの選択肢しかありません。たとえば、{0, 1}、{偽, 真}、{負, 正} などです。 ここで、成人の従業員の人口統計データや雇用データが含まれているデータセットに基づいて収入のレベルを予測するために、二項変数 {“<=50K”, “>50K”} を使うと想定しましょう。 つまり、年収が 5 万ドル以下の層とその他の層に分類します。 回帰のシナリオの場合と同じく、モデルのトレーニング、データのスコア付け、結果の評価を行います。 おもな違いは、Azure Machine Learning が計算して出力するメトリックの選択です。 使用して収入レベルの予測シナリオを説明するために、 [成人向け](http://archive.ics.uci.edu/ml/datasets/Adult) データセット、Azure Machine Learning の実験を作成し、2 クラス ロジスティック回帰モデルでは、一般的に使用される二項分類器のパフォーマンスを評価します。

###実験の作成###
Azure Machine Learning Studio で以下のモジュールをワークスペースに追加します。

- 米国国勢調査局提供の、成人収入に関する二項分類データセット
- [2 クラス ロジスティック回帰][2 つのクラスのロジスティック-回帰]
- [モデルのトレーニング][モデルのトレーニング]
- [モデルのスコア付け][モデルのスコア付け]
- [モデルの評価][評価モデル]

図 5 のように、ポートに接続し、[モデルのトレーニング] [モデルのトレーニング] モジュールのラベル列を設定 *収入*します。

![二項分類モデルの評価](media/machine-learning-evaluate-model-performance/5.png)

図 5: 二項分類モデルの評価。

###評価結果の確認###
実験を実行すると、[モデルの評価] [- モデルの評価] モジュールの出力ポートをクリックし、選択 *視覚化* (図 7) の評価結果を確認します。 二項分類モデルで使用できる評価メトリックは: *精度*, 、*精度*, 、*ことを思い出してください*, 、*F1 スコア*, 、および *AUC*します。 モジュールはさらに、真陽性、偽陰性、偽陽性、真陰性の数を示す混同行列を出力するだけでなく *ROC*, 、*正確度/再現性*, 、および *リフト* 曲線です。

精度とは、簡単に言えば正しく分類された事例の比率です。 分類モデルを評価するときは通常、精度のメトリックに最初に注目します。 しかし、テスト データのバランスが悪く大半が片方のクラスに属する場合や、片方のクラスのパフォーマンスにおもに関心がある場合は、精度だけで分類モデルのパフォーマンスを評価することはできません。 たとえば、収入レベルの分類シナリオで、99% が年収 5 万ドル以下の層に属するデータをテストしているとしましょう。 どの事例についても、「<=50K」の層を予測すれば 0.99 の精度を達成できます。 この分類モデルのパフォーマンスは非常に高いように思えるかもしれませんが、実際のところ、高収入の人たち (1%) を正確に分類することはできません。

そのため、多角的に評価するには、さらに別のメトリックを計算する必要があります。 そのようなメトリックを詳しく取り上げる前に、二項分類の評価の混同行列について理解しておくことは重要です。 トレーニング セットのクラス ラベルには 2 つの値しかありません。通常は、正の値と負の値です。 分類モデルが正しく予測した正の事例と負の事例のことを、それぞれ真陽性 (TP) と真陰性 (TN) といいます。 また、間違って分類した事例のことを、それぞれ偽陽性 (FP) と偽陰性 (FN) といいます。 混同行例とは、簡単に言えば、この 4 つの分類に該当する事例の数をまとめた表です。 Azure Machine Learning では、データセット内の 2 つのクラスが正のクラスとして自動的に設定されます。 クラスのラベルがブール値または整数値であれば、「真」または「1」のラベルの事例が正のクラスになります。 収入のデータセットの場合のようにラベルが文字列であれば、ラベルがアルファベット順に並べられ、最初のレベルが負のクラス、2 番目のレベルが正のクラスになります。

![二項分類の混同行列](media/machine-learning-evaluate-model-performance/6a.png)

図 6: 二項分類の混同行列。

収入の分類問題に戻りましょう。分類モデルのパフォーマンスを評価するために、いくつかのことを確認したいと思います。 まず思い浮かぶのは次のような点です。モデルによって年収が 5 万ドル超と予測された人 (TP+FP) のうち、その予測が正しかった人 (TP) の割合はどれほどでしょうか。 この質問を見てして応答することができます、 **精度** 正しく分類された陽性の比率は、モデルの: TP/(TP+FP) です。 また、こんな点もあります。年収が 5 万ドル超の人 (TP+FN) のうち、この分類モデルによって正しく分類された人 (TP) の割合はどれほどでしょうか。 これは実際に、 **ことを思い出してください**, 、または真陽性率: 分類器の TP/(TP+FN) です。 お気づきかもしれませんが、精度と再現率はトレードオフの関係になっています。 たとえば、比較的バランスの取れたデータセットの場合、ほとんどを正の事例として予測する分類モデルは、再現率が高くなります。一方、負の事例の多くが間違って分類され、偽陽性の数が多くなるので、精度は低めになります。 評価結果の出力ページ (図 7 の左上の部分) にある精度/再現率曲線をクリックすれば、この 2 つのメトリックがどう変化するかを示すプロットを表示できます。

![二項分類の評価結果](media/machine-learning-evaluate-model-performance/7.png)
図 7: 二項分類の評価結果。

よく使用されるメトリックは、関連するほか、 **F1 スコア**, 、精度と再現率を考慮に入れての両方です。 つまり、その 2 つのメトリックの調和平均であり、F1 = 2 (精度 x 再現率) / (精度 + 再現率) という計算になります。 F1 スコアは、1 つの数字で評価を要約するための便利な方法ですが、分類モデルのパフォーマンスの全体像をつかむには、精度と再現率もあわせて確認することをお勧めします。

さらに、真陽性率と偽陽性率を確認できます、 **受信者操作特性 (ROC)** 曲線と、対応する **領域下曲線 (AUC)** 値。 この曲線が左上隅に近ければ近いほど、分類モデルのパフォーマンスは良好です (つまり、真陽性率が高く、偽陽性率が低くなります)。 ほぼ当てずっぽうのような予測をする傾向の強い分類モデルでは、プロットの対角線に近い曲線になります。

###クロス検証の使用###
回帰の場合と同じく、クロス検証を使用して、データの各サブセットのトレーニング/スコア付け/評価を自動的に反復実行できます。 同様に、[モデルのクロス検証] [クロス検証のモデル] モジュールでは、トレーニングしていないロジスティック回帰モデルとデータセットを使用できます。 ラベル列に設定する必要があります *収入* [モデルのクロス検証] [クロス検証のモデル] モジュールのプロパティでします。 [モデルのクロス検証] [クロス検証のモデル] モジュールのポートを出力するは、実験の実行を右側をクリックすると、平均と標準偏差の各だけでなく、各分割処理の二項分類メトリック値がわかります。 
 
![二項分類モデルのクロス検証](media/machine-learning-evaluate-model-performance/8.png)

図 8: 二項分類モデルのクロス検証。

![二項分類モデルのクロス検証の結果](media/machine-learning-evaluate-model-performance/9.png)

図 9: 二項分類モデルのクロス検証の結果。

##多クラス分類モデルの評価##
この実験では使用して、一般的な [あやめ](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset 3 のさまざまな種類 (クラス) あやめの事例が含まれています。 事例ごとに 4 つの特徴値 (がくの長さ、がくの幅、花弁の長さ、花弁の幅) があります。 前の実験では、同じデータセットを使ってモデルのトレーニングとテストを行いました。 ここでは、[分割] [分割] モジュールを使用して、データの 2 つのサブセットを作成、トレーニングを最初に、スコア付け/評価 2 回目はです。 
Iris データセットはで一般に公開、 [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), 、[リーダー] [リーダー] モジュールを使用してダウンロードできます。

###実験の作成###
Azure Machine Learning Studio で以下のモジュールをワークスペースに追加します。

- [リーダー][リーダー]
- [多クラス デシジョン フォレスト][多クラス デシジョン フォレスト]
- [分割][分割]
- [モデルのトレーニング][モデルのトレーニング]
- [モデルのスコア付け][モデルのスコア付け]
- [モデルの評価][評価モデル]

図 10 のようにポートを接続します。

[モデルのトレーニング] の [モデルのトレーニング] モジュールのラベル列のインデックスを 5 に設定します。 このデータセットにはヘッダー行がありませんが、クラス ラベルが第 5 列にあります。

[リーダー] [リーダー] モジュールをクリックし、設定、 *データソース* プロパティを *HTTP 経由で Web URL*, 、および *URL* を http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data にします。

使用する事例の割合を設定、[分割] [分割] モジュール (0.7 など) でトレーニングします。
 
![多クラス分類モデルの評価](media/machine-learning-evaluate-model-performance/10.png)

図 10: 多クラス分類モデルの評価

###評価結果の確認###
実験を実行し、[モデルの評価] [- モデルの評価] の出力ポートをクリックします。 この場合は、評価結果が混同行列の形式で表示されます。 この行列で、3 つのクラスすべての実際の事例と予測の事例を確認できます。
 
![多クラス分類の評価結果](media/machine-learning-evaluate-model-performance/11.png)

図 11: 多クラス分類の評価結果。

###クロス検証の使用###
前述のように、繰り返しのトレーニング、スコア付け/評価を自動的にモジュールを使用して、[モデルのクロス検証] [クロス検証のモデル] を実行できます。 データセット、トレーニングしていないモデル、および [モデルのクロス検証] [クロス検証のモデル] モジュール必要があります (次の図を参照してください)。 もう一度 (列のインデックスを 5 ここでは) [モデルのクロス検証] [クロス検証のモデル] モジュールのラベル列を設定する必要があります。 実験を実行し、右クリックすると出力の [モデルのクロス検証] [クロス検証のモデル] のポートを各分割処理だけでなく、平均偏差と標準偏差のメトリックの値を検査することができます。 この場合に表示されるメトリックは、二項分類の例で取り上げたメトリックと同じです。 ただし、多クラス分類では、真陽性/陰性、偽陽性/陰性の計算がクラスごとに行われ、正のクラスまたは負のクラスの全体の値はありません。 たとえば、Iris-setosa クラスの精度や再現率を計算する場合は、それが正のクラスで他のすべてが負のクラスであるという前提で処理が行われます。
 
![多クラス分類モデルのクロス検証](media/machine-learning-evaluate-model-performance/12.png)

図 12. 多クラス分類モデルのクロス検証。


![多クラス分類モデルのクロス検証の結果](media/machine-learning-evaluate-model-performance/13.png)

図 13. 多クラス分類モデルのクロス検証の結果。


<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/
 
